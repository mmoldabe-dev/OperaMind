"""
–°–∏—Å—Ç–µ–º–∞ –æ—á–µ—Ä–µ–¥–µ–π –¥–ª—è —Ñ–æ–Ω–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç threading –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
"""

import threading
import queue
import time
from datetime import datetime
from models import db, Conversation, Analysis
from transcriber import transcribe_audio_file, transcribe_from_text
from analyzer import analyze_transcript
import json
import os

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á
task_queue = queue.Queue()
processing_threads = []
queue_lock = threading.Lock()

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
queue_stats = {
    'total_processed': 0,
    'total_errors': 0,
    'currently_processing': 0,
    'queue_size': 0
}


class ProcessingTask:
    """–ó–∞–¥–∞—á–∞ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É"""
    def __init__(self, conversation_id, filepath, filename, is_text=False):
        self.conversation_id = conversation_id
        self.filepath = filepath
        self.filename = filename
        self.is_text = is_text
        self.created_at = datetime.utcnow()
        self.status = 'queued'
        self.error = None


def process_task(task, app):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–∏"""
    with app.app_context():
        try:
            print(f"\n{'='*70}")
            print(f"üîÑ –û–ë–†–ê–ë–û–¢–ö–ê: {task.filename}")
            print(f"{'='*70}")
            
            conversation = db.session.get(Conversation, task.conversation_id)
            if not conversation:
                raise Exception("–†–∞–∑–≥–æ–≤–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ë–î")
            
            # –≠–¢–ê–ü 1: –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø
            print("\nüìù –≠–¢–ê–ü 1: –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø")
            conversation.status = 'transcribing'
            db.session.commit()
            
            if task.is_text:
                with open(task.filepath, 'r', encoding='utf-8') as f:
                    structured_transcript = transcribe_from_text(f.read())
                print("   ‚úì –¢–µ–∫—Å—Ç –∑–∞–≥—Ä—É–∂–µ–Ω")
            else:
                structured_transcript = transcribe_audio_file(task.filepath)
            
            if not structured_transcript:
                raise Exception("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            try:
                data_tr = json.loads(structured_transcript)
                if isinstance(data_tr, dict) and 'meta' in data_tr:
                    conversation.duration = int(data_tr['meta'].get('duration_sec', 0))
            except:
                pass
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–ª–æ—Å–∫–∏–π —Ç–µ–∫—Å—Ç
            flat_text = None
            try:
                data_tr = json.loads(structured_transcript)
                if isinstance(data_tr, dict) and 'text' in data_tr:
                    flat_text = data_tr.get('text')
                else:
                    flat_text = structured_transcript
            except:
                flat_text = structured_transcript
            
            # –≠–¢–ê–ü 2: –ê–ù–ê–õ–ò–ó
            print("\nü§ñ –≠–¢–ê–ü 2: –ê–ù–ê–õ–ò–ó")
            conversation.status = 'analyzing'
            db.session.commit()
            
            analysis_result = analyze_transcript(flat_text)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            analysis = Analysis(
                conversation_id=conversation.id,
                transcript=structured_transcript,
                topic=analysis_result.get('topic'),
                category=analysis_result.get('category'),
                sentiment=analysis_result.get('sentiment'),
                urgency=analysis_result.get('urgency'),
                keywords=json.dumps(analysis_result.get('keywords', []), ensure_ascii=False),
                summary=analysis_result.get('summary'),
                detailed_analysis=analysis_result.get('detailed_analysis'),
                operator_quality=analysis_result.get('operator_quality'),
                recommendations=analysis_result.get('recommendations')
            )
            
            conversation.status = 'completed'
            db.session.add(analysis)
            db.session.commit()
            
            print(f"\n‚úÖ –ó–ê–í–ï–†–®–ï–ù–û: {task.filename}")
            print(f"{'='*70}\n")
            
            with queue_lock:
                queue_stats['total_processed'] += 1
            
        except Exception as e:
            print(f"\n‚ùå –û–®–ò–ë–ö–ê: {task.filename}")
            print(f"   {str(e)}")
            print(f"{'='*70}\n")
            
            with app.app_context():
                conversation = db.session.get(Conversation, task.conversation_id)
                if conversation:
                    conversation.status = 'error'
                    db.session.commit()
            
            task.error = str(e)
            with queue_lock:
                queue_stats['total_errors'] += 1


def worker_thread(app):
    """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏"""
    print("üîµ –†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –∑–∞–ø—É—â–µ–Ω")
    
    while True:
        try:
            # –ñ–¥–µ–º –∑–∞–¥–∞—á—É –∏–∑ –æ—á–µ—Ä–µ–¥–∏
            task = task_queue.get(timeout=1)
            
            with queue_lock:
                queue_stats['currently_processing'] += 1
                queue_stats['queue_size'] = task_queue.qsize()
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
            process_task(task, app)
            
            # –ó–∞–≤–µ—Ä—à–∞–µ–º
            task_queue.task_done()
            
            with queue_lock:
                queue_stats['currently_processing'] -= 1
                queue_stats['queue_size'] = task_queue.qsize()
                
        except queue.Empty:
            # –û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞, –∂–¥–µ–º
            with queue_lock:
                queue_stats['queue_size'] = task_queue.qsize()
            continue
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—á–µ–º –ø–æ—Ç–æ–∫–µ: {e}")
            with queue_lock:
                queue_stats['currently_processing'] -= 1


def init_queue_system(app, num_workers=None):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –æ—á–µ—Ä–µ–¥–µ–π"""
    if num_workers is None:
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 2 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞
        num_workers = int(os.getenv('QUEUE_WORKERS', '2'))
    
    print(f"\n{'='*70}")
    print(f"üöÄ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–ò–°–¢–ï–ú–´ –û–ß–ï–†–ï–î–ï–ô")
    print(f"{'='*70}")
    print(f"   –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤: {num_workers}")
    print(f"{'='*70}\n")
    
    # –°–æ–∑–¥–∞–µ–º —Ä–∞–±–æ—á–∏–µ –ø–æ—Ç–æ–∫–∏
    for i in range(num_workers):
        thread = threading.Thread(
            target=worker_thread,
            args=(app,),
            daemon=True,
            name=f"QueueWorker-{i+1}"
        )
        thread.start()
        processing_threads.append(thread)
    
    print(f"‚úÖ –°–∏—Å—Ç–µ–º–∞ –æ—á–µ—Ä–µ–¥–µ–π –∑–∞–ø—É—â–µ–Ω–∞: {num_workers} –ø–æ—Ç–æ–∫–æ–≤\n")


def add_to_queue(conversation_id, filepath, filename, is_text=False):
    """–î–æ–±–∞–≤–∏—Ç—å –∑–∞–¥–∞—á—É –≤ –æ—á–µ—Ä–µ–¥—å"""
    task = ProcessingTask(conversation_id, filepath, filename, is_text)
    task_queue.put(task)
    
    with queue_lock:
        queue_stats['queue_size'] = task_queue.qsize()
    
    print(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å: {filename} (–ø–æ–∑–∏—Ü–∏—è: {task_queue.qsize()})")
    return task


def get_queue_status():
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –æ—á–µ—Ä–µ–¥–∏"""
    with queue_lock:
        return {
            'queue_size': task_queue.qsize(),
            'currently_processing': queue_stats['currently_processing'],
            'total_processed': queue_stats['total_processed'],
            'total_errors': queue_stats['total_errors'],
            'workers_active': len([t for t in processing_threads if t.is_alive()])
        }


def wait_for_queue():
    """–î–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á"""
    task_queue.join()